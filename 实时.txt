1. 复用离线数仓数据采集通道，组成Lambda架构，以Kafka作为数据通道，进行原始数据的备份与展示
2. 从业务数据中过滤出维度信息，动态维护维度的配置信息表，使用FlinkCDC实时拉取数据，最后根据配置信息进
行维表数据过滤
3. 选用HBase进行存储，选用Redis做为外部独立缓存组件，解决数据一致性问题，采用延迟双删策略同步Hbase
和Redis数据
4. 为避免网络波动以及线程资源竞争带来的数据乱序，最终导致维度数据丢失问题，使用Flink富含数并在open方
法中进行维度配置信息数据预加载
5. 为避免HBase查询延迟问题，获取HBase连接时使用异步API，解决线程长时间空转等待问题。
6. 对用户行为数据使用Flink OutputTag进行分流，同时使用Flink State进行新老访客状态标记修复
7. 对于复杂业务过程，使用Interval Join、Left Join等方式对多条业务数据进行关联
8. 对于包含多个状态的业务数据，根据特定字段的变化规律进行筛选，最后过滤掉无效数据或为下游添加新字段
9. 同时传入一份明细数据到Doris，作为即席查询应急方案
10. 根据指标体系，对数据明细进行过滤，类型转换，设置水印，分组，开窗，设置状态，编写聚合函数，按照不
同粒度需求进行聚合操作
11. 对于动态粒度的指标，使用IkAnalyzer进行分词处理
12. 聚合后的数据进行维度关联，作为宽表写入Doris中


1.用户变动统计 2.用户留存率 3.用户新增活跃统计
4.用户行为漏斗分析 5.新增下单用户统计 6.最近7日内连续3日下单用户数
7.下单到支付时间间隔平均值 8.各省份交易统计 9.最近30日每个品牌的退单率